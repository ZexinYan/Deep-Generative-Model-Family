# Deep Generative Model Family

Deep generative models have revolutionized the field of artificial intelligence by enabling the creation of realistic and high-quality synthetic data. This project aims to implement various deep generative models. Instead of focusing on improving the performance of models, this project implements the simplest models to solve the task of generating hand-written images (MNIST) by showing how these models train and sample.

## Model Family

1. Auto-Regressive Model

- PixelCNN

2. Generative Adversarial Networks

- Wasserstein GAN

3. Variational AutoEncoder

- Mixture Gaussian Model

4. Energy-Based Model

- Contrastive Divergence Learning via Metropolis-Hastings MCMC

5. Normalized Flow Model

- Multi Scale Normalized Flow Model

6. Diffusion Model

- DDPM

# Reference

- [Stanford CS236](https://deepgenerativemodels.github.io/syllabus.html)
- [Tutorial 8: Deep Energy-Based Generative Models](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html)
- [Tutorial 11: Normalizing Flows for image modeling](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial11/NF_image_modeling.html)
- [Tutorial 12: Autoregressive Image Modeling](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial12/Autoregressive_Image_Modeling.html)
